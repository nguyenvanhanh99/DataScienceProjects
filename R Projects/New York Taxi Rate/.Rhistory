best_seednumber = 1234
best_rmse = 0
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:10, 1),
eta = runif(1, .01, .3),
gamma = runif(1, 0.0, 0.2),
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:40, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 10
cv.nfold = 5
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
max_rmse = max(mdcv$evaluation_log$test_rmse_mean)
max_rmse_index = which.max(mdcv$evaluation_log$test_rmse_mean)
if (max_rmse < best_rmse) {
best_rmse = max_rmse
best_rmse_index = max_rmse_index
best_seednumber = seed.number
best_param = param
}
}
best_param = list()
best_seednumber = 1234
best_rmse = 0
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:10, 1),
eta = runif(1, .01, .3),
gamma = runif(1, 0.0, 0.2),
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:40, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 60
cv.nfold = 10
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
max_rmse = max(mdcv$evaluation_log$test_rmse_mean)
max_rmse_index = which.max(mdcv$evaluation_log$test_rmse_mean)
if (max_rmse < best_rmse) {
best_rmse = max_rmse
best_rmse_index = max_rmse_index
best_seednumber = seed.number
best_param = param
}
}
best_param
View(param)
best_param = list()
best_seednumber = 1234
best_rmse = 0
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:10, 1),
eta = runif(1, .01, .3),
gamma = runif(1, 0.0, 0.2),
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:40, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 100
cv.nfold = 8
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
max_rmse = max(mdcv$evaluation_log$test_rmse_mean)
max_rmse_index = which.max(mdcv$evaluation_log$test_rmse_mean)
if (max_rmse < best_rmse) {
best_rmse = max_rmse
best_rmse_index = max_rmse_index
best_seednumber = seed.number
best_param = param
}
}
best_param = list()
best_seednumber = 1234
best_rmse = 0
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:10, 1),
eta = runif(1, .01, .3),
gamma = runif(1, 0.0, 0.2),
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:40, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 70
cv.nfold = 10
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
max_rmse = max(mdcv$evaluation_log$test_rmse_mean)
max_rmse_index = which.max(mdcv$evaluation_log$test_rmse_mean)
if (max_rmse < best_rmse) {
best_rmse = max_rmse
best_rmse_index = max_rmse_index
best_seednumber = seed.number
best_param = param
}
}
View(param)
nround = best_rmse_index
mdcv$evaluation_log$test_rmse_mean
max(mdcv$evaluation_log$test_rmse_mean)
View(param)
cv.nround = 80
best_param = list()
best_seednumber = 1234
best_rmse = 0
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:10, 1),
eta = runif(1, .01, .3),
gamma = runif(1, 0.0, 0.2),
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:40, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 80
cv.nfold = 10
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
max_rmse = min(mdcv$evaluation_log$test_rmse_mean)
max_rmse_index = which.min(mdcv$evaluation_log$test_rmse_mean)
if (max_rmse < best_rmse) {
best_rmse = max_rmse
best_rmse_index = max_rmse_index
best_seednumber = seed.number
best_param = param
}
}
best_param = list()
best_seednumber = 1234
best_rmse = 0
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:10, 1),
eta = runif(1, .01, .3),
gamma = runif(1, 0.0, 0.2),
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:40, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 80
cv.nfold = 10
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
max_rmse = min(mdcv$evaluation_log$test_rmse_mean)
max_rmse_index = which.min(mdcv$evaluation_log$test_rmse_mean)
if (max_rmse < best_rmse) {
best_rmse = max_rmse
best_rmse_index = max_rmse_index
best_seednumber = seed.number
best_param = param
}
}
best_param = list()
best_seednumber = 1234
best_rmse = Inf
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:8, 1),
eta = runif(1, .2, .3),
gamma = runif(1, 0.0, 0.1),
subsample = runif(1, .4, .8),
colsample_bytree = runif(1, .6, .8),
min_child_weight = sample(1:20, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 100
cv.nfold = 10
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
min_rmse = min(mdcv$evaluation_log$test_rmse_mean)
min_rmse_index = which.min(mdcv$evaluation_log$test_rmse_mean)
if (min_rmse < best_rmse) {
best_rmse = min_rmse
best_rmse_index = min_rmse_index
best_seednumber = seed.number
best_param = param
}
}
View(best_param)
nround = best_rmse_index
set.seed(best_seednumber)
md <- xgb.train(data=train_xgb, params=best_param, nrounds=nround, nthread=3)
xgb.predict <- predict(md , test_xgb)
postResample(xgb.pred, testDataNonTrans$fare_amount)
postResample(xgb.predict, testDataNonTrans$fare_amount)
View(cvResults)
train <- Matrix(as.matrix(trainData), sparse = TRUE)
#train_smote <- Matrix(as.matrix(train_smote), sparse = TRUE)
test <- Matrix(as.matrix(testData), sparse = TRUE)
cv <- Matrix(as.matrix(cvData), sparse = TRUE)
train_xgb <- xgb.DMatrix(data = train[,-i], label = train[,i])
#train_smote_xgb <- xgb.DMatrix(data = train_smote[,-i], label = train_smote[,i])
test_xgb <- xgb.DMatrix(data = test[,-i], label = test[,i])
cv_xgb <- xgb.DMatrix(data = cv[,-i], label = cv[,i])
watchlist <- list(train  = train_xgb, cv = cv_xgb)
best_param = list()
best_seednumber = 1234
best_rmse = Inf
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:8, 1),
eta = runif(1, .2, .3),
gamma = runif(1, 0.0, 0.1),
subsample = runif(1, .4, .8),
colsample_bytree = runif(1, .6, .8),
min_child_weight = sample(1:20, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 100
cv.nfold = 10
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
min_rmse = min(mdcv$evaluation_log$test_rmse_mean)
min_rmse_index = which.min(mdcv$evaluation_log$test_rmse_mean)
if (min_rmse < best_rmse) {
best_rmse = min_rmse
best_rmse_index = min_rmse_index
best_seednumber = seed.number
best_param = param
}
}
nround = best_rmse_index
set.seed(best_seednumber)
mdN <- xgb.train(data=train_xgb, params=best_param, nrounds=nround, nthread=3)
xgb.predict <- predict(mdN , test_xgb)
postResample(xgb.predict, testData$fare_amount)
View(testData)
xgb.predict
View(testData)
View(trainData)
i <- grep("fare_amount", colnames(trainData)) # Get index Class column
train_xgb <- xgb.DMatrix(data = train[,-i], label = train[,i])
#train_smote_xgb <- xgb.DMatrix(data = train_smote[,-i], label = train_smote[,i])
test_xgb <- xgb.DMatrix(data = test[,-i], label = test[,i])
cv_xgb <- xgb.DMatrix(data = cv[,-i], label = cv[,i])
best_param = list()
best_seednumber = 1234
best_rmse = Inf
best_rmse_index = 0
for (iter in 1:2) {
param <- list(objective = "reg:linear",
eval_metric = "rmse",
max_depth = sample(6:8, 1),
eta = runif(1, .2, .3),
gamma = runif(1, 0.0, 0.1),
subsample = runif(1, .4, .8),
colsample_bytree = runif(1, .6, .8),
min_child_weight = sample(1:20, 1),
max_delta_step = sample(1:10, 1)
)
cv.nround = 100
cv.nfold = 10
seed.number = sample.int(10000, 1)[[1]]
set.seed(seed.number)
mdcv <- xgb.cv(data=train_xgb, params = param, nthread=3,
nfold=cv.nfold, nrounds=cv.nround,
verbose = T, early.stopping.round=8, maximize=FALSE)
min_rmse = min(mdcv$evaluation_log$test_rmse_mean)
min_rmse_index = which.min(mdcv$evaluation_log$test_rmse_mean)
if (min_rmse < best_rmse) {
best_rmse = min_rmse
best_rmse_index = min_rmse_index
best_seednumber = seed.number
best_param = param
}
}
nround = best_rmse_index
set.seed(best_seednumber)
mdN <- xgb.train(data=train_xgb, params=best_param, nrounds=nround, nthread=3)
xgb.predict <- predict(mdN , test_xgb)
postResample(xgb.predict, testData$fare_amount)
test <- read.table(file="test.csv", header=T, sep=",")
str(test)
head(test,5)
library(lubridate)
test[,'pickup_weekDay']=wday(as.POSIXlt(test$pickup_datetime))
test[,'pickup_year']=year(as.POSIXlt(test$pickup_datetime))
test[,'pickup_month']=month(as.POSIXlt(test$pickup_datetime))
test[,'pickup_hour']=hour(as.POSIXct(test$pickup_datetime, format="%Y-%m-%d %H:%M:%S"))
test[,'pickup_minute']=minute(as.POSIXct(test$pickup_datetime, format="%Y-%m-%d %H:%M:%S"))
test$key = NULL
save(test,file='test.Rda')
library(geosphere)
tripDistance = c()
for (i in (1:nrow(test))){
tripDistance = c(tripDistance,distm(c(test[i,3],test[i,4]),c(test[i,5],test[i,6]),fun = distHaversine))
#print(paste(i,tripDistance))
}
test=cbind(test,tripDistance)
View(test)
View(trainDataNonTrans)
test <- read.table(file="test.csv", header=T, sep=",")
test[,'pickup_weekDay']=wday(as.POSIXlt(test$pickup_datetime))
test[,'pickup_year']=year(as.POSIXlt(test$pickup_datetime))
test[,'pickup_month']=month(as.POSIXlt(test$pickup_datetime))
test[,'pickup_hour']=hour(as.POSIXct(test$pickup_datetime, format="%Y-%m-%d %H:%M:%S"))
test[,'pickup_minute']=minute(as.POSIXct(test$pickup_datetime, format="%Y-%m-%d %H:%M:%S"))
test$key = NULL
library(geosphere)
tripDistance = c()
for (i in (1:nrow(test))){
tripDistance = c(tripDistance,distm(c(test[i,2],test[i,3]),c(test[i,4],test[i,5]),fun = distHaversine))
#print(paste(i,tripDistance))
}
test=cbind(test,tripDistance)
View(test)
train$pickup_datetime = NULL
#load('train.Rda')
test$pickup_datetime = NULL
test$pickup_weekDay = factor(test$pickup_weekDay)
test$pickup_year = factor(test$pickup_year)
test$pickup_month = factor(test$pickup_month)
test$pickup_hour = factor(test$pickup_hour)
test$pickup_minute = factor(test$pickup_minute)
xgb.submit <- predict(rf_default, test)
xgb.submit <- predict(md, test)
test_xgb <- xgb.DMatrix(data = test)
test <- Matrix(as.matrix(test), sparse = TRUE)
test_xgb <- xgb.DMatrix(data = test)
xgb.submit <- predict(md, test_xgb)
submission1 <- read.table(file="sample_submission.csv", header=T, sep=",")
submission1$fare_amount = xgb.submit
View(submission1)
write.csv(submission1,file="submissionXGB.csv")
test[,1]
test <- read.table(file="test.csv", header=T, sep=",")
submission1 =cbind(test$key,xgb.submit)
View(submission1)
View(test)
submission1 =cbind(test[,1],xgb.submit)
View(submission1)
submission1 =cbind(test,xgb.submit)
View(submission1)
submission2 = submission1[,c(1,8)]
View(submission2)
View(submission2)
names(submission2)[names(submission2) == 'xgb.submit'] <- 'fare_amount'
View(submission2)
write.csv(submission2,file="submissionXGB.csv")
write.csv(submission2,file="submissionXGB.csv",row.names = FALSE)
write.csv(submission2,file="submissionTest.csv",row.names = FALSE,index=FALSE)
View(test)
test[,1]
View(submission1)
View(submission2)
write.csv(submission2,file="submissionTest.csv",row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
train <- read.table(file="train.csv",nrows = 100000, header=T, sep=",")
train <- read.table(file="train.csv",nrows = 100000, header=T, sep=",")
library(lubridate)
train[,'pickup_weekDay']=wday(as.POSIXlt(train$pickup_datetime))
train[,'pickup_day']=day(as.POSIXlt(train$pickup_datetime))
View(train)
train[,'pickup_year']=year(as.POSIXlt(train$pickup_datetime))
train[,'pickup_month']=month(as.POSIXlt(train$pickup_datetime))
train[,'pickup_hour']=hour(as.POSIXct(train$pickup_datetime, format="%Y-%m-%d %H:%M:%S"))
train[,'pickup_minute']=minute(as.POSIXct(train$pickup_datetime, format="%Y-%m-%d %H:%M:%S"))
train$key = NULL
for (name in c('pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude')){
x <- train[,name]
qnt <- quantile(x, probs=c(.25, .75), na.rm = T)
caps <- quantile(x, probs=c(.05, .95), na.rm = T)
H <- 1.5 * IQR(x, na.rm = T)
x[x < (qnt[1] - H)] <- caps[1]
x[x > (qnt[2] + H)] <- caps[2]
train[,name] = x
}
library(geosphere)
tripDistance = c()
for (i in (1:nrow(train))){
tripDistance = c(tripDistance,distm(c(train[i,3],train[i,4]),c(train[i,5],train[i,6]),fun = distHaversine))
#print(paste(i,tripDistance))
}
train[,'tripDistance'] = tripDistance
View(train)
train$pickup_datetime = NULL
train$pickup_weekDay = factor(train$pickup_weekDay)
train$pickup_day = factor(train$pickup_day)
train$pickup_year = factor(train$pickup_year)
train$pickup_month = factor(train$pickup_month)
train$pickup_hour = factor(train$pickup_hour)
train$pickup_minute = factor(train$pickup_minute)
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(train,2,pMiss)
rm(caps,H,i,name,qnt,tripDistance,x)
set.seed(1900)
library(caret)
inTrain <- createDataPartition(y = train$fare_amount, p = .6, list = F)
trainData <- train[inTrain,]
testcvData <- train[-inTrain,]
inTest <- createDataPartition(y = testcvData$fare_amount, p = .5, list = F)
testData <- testcvData[inTest,]
cvData <- testcvData[-inTest,]
#train$AMI_FLAG <- as.factor(train$AMI_FLAG)
rm(inTrain, inTest, testcvData)
control <- trainControl(method="cv", number=2,verboseIter =TRUE)
seed <- 7
metric <- "RMSE"
set.seed(seed)
mtry <- ncol(trainData)/3
tunegrid <- expand.grid(.mtry=mtry)
rf_default <- train(fare_amount~., data=trainData, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
ncol(trainData)/3
View(trainData)
control <- trainControl(method="cv", number=5,verboseIter =TRUE)
seed <- 7
metric <- "RMSE"
set.seed(seed)
mtry <- ncol(trainData)/3
tunegrid <- expand.grid(.mtry=mtry)
rf_default <- train(fare_amount~., data=trainData, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
table(train$fare_amount)
complete.cases(train$fare_amount)
sum(complete.cases(train$fare_amount))
hist(train$fare_amount)
```{r}
control <- trainControl(method="cv", number=5,verboseIter =TRUE)
seed <- 7
metric <- "RMSE"
set.seed(seed)
mtry <- 4
tunegrid <- expand.grid(.mtry=mtry)
rf_default <- train(fare_amount~., data=trainData, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
is.na(train$fare_amount)
sum(is.na(train$fare_amount))
removingNonNAMissing = function (dataframe,datacolumn){
toremove = c()
for (i in 1:100000){
#print(nchar(toString(dataframe[i,datacolumn])))
if(nchar(toString(dataframe[i,datacolumn]))==0){
toremove = c(i,toremove)
}
}
return (toremove)
}
removingNonNAMissing(train,"fare_amount")
control <- trainControl(method="cv", number=5,verboseIter =TRUE)
seed <- 7
metric <- "RMSE"
set.seed(seed)
mtry <- 4
tunegrid <- expand.grid(.mtry=mtry)
rf_default <- train(fare_amount~., data=trainData, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
removingNonNAMissing(train,"fare_amount")
removingNonNAMissing(trainData,"fare_amount")
colnames(train)
removingNonNAMissing(trainData,"pickup_longitude")
colnames(train)
removingNonNAMissing(trainData,"pickup_latitude")
for (name in colnames(train)){
removingNonNAMissing(train,name)
}
for (name in colnames(train)){
x=removingNonNAMissing(train,name)
print(x)
}
for (name in colnames(train)){
#x=removingNonNAMissing(train,name)
print(name)
print(is.na(train[,name]))
}
