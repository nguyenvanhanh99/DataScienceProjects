library(VIM)
aggr_plot <- aggr(numeric10, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(numeric10), cex.axis=.7, gap=3, ylab=c("Histogram of missing data in numeric10","Pattern"))
aggr_plot <- aggr(numeric20, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(numeric20), cex.axis=.7, gap=3, ylab=c("Histogram of missing data in numeric20","Pattern"))
aggr_plot <- aggr(numeric30, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(numeric30), cex.axis=.7, gap=3, ylab=c("Histogram of missing data in numeric30","Pattern"))
aggr_plot <- aggr(numeric40, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(numeric40), cex.axis=.7, gap=3, ylab=c("Histogram of missing data in numeric 40","Pattern"))
install.packages("VIM")
numeric10$LotFrontage = NULL
dim(numeric10)
row.has.na <- apply(numeric10, 1, function(x){any(is.na(x))})
sum(row.has.na)
numeric10 <- numeric10[!row.has.na,]
dim(numeric10)
numeric30$GarageYrBlt = NULL
dim(numeric10)
row.has.na <- apply(numeric30, 1, function(x){any(is.na(x))})
sum(row.has.na)
numeric30 <- numeric30[!row.has.na,]
dim(numeric30)
corrplot(cor(numeric10))
corrplot(cor(numeric30))
names(numeric20)
#numeric20$MSSubClass = NULL
#numeric20$OverallCond = NULL
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric20$BedroomAbvGr = NULL
numeric20$KitchenAbvGr = NULL
names(numeric30)
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric40)
#numeric30[,!c("BedroomAbvGr"," = NULL
#numeric30$KitchenAbvGr = NULL
#names(numeric30)
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric40)
numeric30[,!c("OpenPorchSF","EnclosedPorch")]
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric40)
numeric30[c("OpenPorchSF","EnclosedPorch")]
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric40)
numeric30[,c("OpenPorchSF","EnclosedPorch")]
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric40)
numeric30[,c(OpenPorchSF,EnclosedPorch)]
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric40)
numeric30[,c('OpenPorchSF','EnclosedPorch')]
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric40)
numeric40[,c('OpenPorchSF','EnclosedPorch')]
#numeric30$KitchenAbvGr = NULL
names(numeric40)
names(numeric20)
numeric20$BsmtFinSF2 = NULL
numeric20$LowQualFinSF = NULL
numeric20$BsmtHalfBath = NULL
names(numeric20)
names(numeric30)
numeric30$BedroomAbvGr = NULL
numeric30$KitchenAbvGr = NULL
names(numeric30)
names(numeric40)
numeric40 = numeric40[,c('OpenPorchSF','EnclosedPorch')]
#numeric30$KitchenAbvGr = NULL
names(numeric40)
dim(numeric10)[1]
dim(numeric10)[2]+dim(numeric20)[2]+dim(numeric30)[2]+dim(numeric40)[2]
dim(numeric10)[2]
#+dim(numeric20)[2]+dim(numeric30)[2]+dim(numeric40)[2]
dim(numeric10)[2]
+dim(numeric20)[2]
#+dim(numeric30)[2]+dim(numeric40)[2]
dim(numeric10)[2]
+dim(numeric20)[2]
+dim(numeric30)[2]
+dim(numeric40)[2]
correlationMatrix <- cor(numeric10)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
install.packages(earth)
library(earth)
install.packages('earth')
library(earth)
model <- earth(SalePrice ~ ., data=numeric10) # build model
ev <- evimp (model)
print(ev)
plot(ev)
summary(trainFactor)
plot(cars)
setwd("C://Users//conne//Desktop//DataMining")
getwd()
# read in OrderBreakdown.txt file into R as a data.frame named "data"
train <- read.table(file="train.csv", header=T, sep=",")
test <- read.table(file="test.csv", header=T, sep=",")
#head(train,5)
#names(train)
str(train)
trainFirst20 = train[,(1:20)]
train21to40 = train[,(21:40)]
train41to60 = train[,(41:60)]
train61to81 = train[,(61:81)]
names(trainFirst20)
names(train21to40)
names(train41to60)
names(train61to81)
trainFirst20["SalePrice"] = train$SalePrice
train21to40["SalePrice"] = train$SalePrice
train41to60["SalePrice"] = train$SalePrice
train61to81["SalePrice"] = train$SalePrice
str()
summary(trainFactor)
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(trainFactor,2,pMiss)
trainFactor$Alley = NULL
trainFactor$FireplaceQu = NULL
trainFactor$GarageType = NULL
trainFactor$GarageFinish = NULL
trainFactor$GarageQual = NULL
trainFactor$GarageType = NULL
trainFactor$MiscFeature = NULL
trainFactor$Fence =NULL
trainFactor$PoolQC = NULL
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(trainFactor,2,pMiss)
trainFactor$Alley = NULL
trainFactor$FireplaceQu = NULL
trainFactor$GarageType = NULL
trainFactor$GarageFinish = NULL
trainFactor$GarageQual = NULL
trainFactor$GarageType = NULL
trainFactor$MiscFeature = NULL
trainFactor$Fence =NULL
trainFactor$PoolQC = NULL
trainFactor$GarageCond = NULL
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(trainFactor,2,pMiss)
#numeric10$LotFrontage = NULL
dim(trainFactor)
row.has.na <- apply(trainFactor, 1, function(x){any(is.na(x))})
sum(row.has.na)
numeric10 <- trainFactor[!row.has.na,]
dim(trainFactor)
#numeric10$LotFrontage = NULL
dim(trainFactor)
row.has.na <- apply(trainFactor, 1, function(x){any(is.na(x))})
sum(row.has.na)
trainFactor <- trainFactor[!row.has.na,]
dim(trainFactor)
#numeric10$LotFrontage = NULL
dim(trainFactor)
row.has.na <- apply(trainFactor, 1, function(x){any(is.na(x))})
sum(row.has.na)
trainFactor <- trainFactor[!row.has.na,]
dim(trainFactor)
head(trainFactor)
setwd("C://Users//conne//Documents//Data Science//Profile//Git//R Projects//Housing Prediction")
getwd()
# read in OrderBreakdown.txt file into R as a data.frame named "data"
train <- read.table(file="train.csv", header=T, sep=",")
test <- read.table(file="test.csv", header=T, sep=",")
#head(train,5)
#names(train)
str(train)
columnNames = names(train)
print(columnNames)
#Initializing the separate dataframe to NULL so that in case of any error they don't keep previous records
trainNumeric = NULL
trainFactor = NULL
#Iterating over column names and putting it into appropriate basket
for (name in columnNames){
print(is.null(trainFactor))
if('factor' == toString(class(train[[name]]))){
if(is.null(trainFactor)){
trainFactor = train[name]
}
trainFactor[name] = train[[name]]
} else{
if(is.null(trainNumeric)){
trainNumeric = train[name]
}
trainNumeric[name] = train[[name]]
}
}
trainNumeric$X = NULL
trainNumeric$Id = NULL
str(trainNumeric)
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(trainNumeric,2,pMiss)
print('######')
apply(trainFactor,2,pMiss)
trainFactor$PoolQC = NULL
trainFactor$Fence = NULL
trainFactor$MiscFeature = NULL
trainFactor$FireplaceQu = NULL
trainFactor$Alley = NULL
trainNumeric$LotFrontage = NULL
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(trainNumeric,2,pMiss)
print('######')
apply(trainFactor,2,pMiss)
library(VIM)
aggr_plot <- aggr(trainNumeric, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(trainNumeric), cex.axis=.7, gap=3, ylab=c("Histogram of missing data in trainNumeric","Pattern"))
aggr_plot <- aggr(trainFactor, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(trainFactor), cex.axis=.7, gap=3, ylab=c("Histogram of missing data in trainFactor","Pattern"))
require(mice)
imputer <- mice(trainNumeric,m=5,maxit=50,meth='pmm')
summary(imputer)
imputedtrainNumeric = complete(imputer, 1)
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(imputedtrainNumeric,2,pMiss)
require(mice)
imputerF <- mice(trainFactor,m=2,maxit=2,meth='polyreg')
summary(imputerF)
imputedtrainFactor = complete(imputerF, 1)
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(imputedtrainFactor,2,pMiss)
dummyimputedtrainFactor <- fastDummies::dummy_cols(imputedtrainFactor, remove_first_dummy = TRUE)
#results <- fastDummies::dummy_cols(fastDummies_example, remove_first_dummy = TRUE)
print(paste('dimension of imputedtrainFactor = ' ,dim(imputedtrainFactor)))
print(paste('dimension of dummyimputedtrainFactor = ' ,dim(dummyimputedtrainFactor)))
for (name in names(imputedtrainFactor)){
dummyimputedtrainFactor[name] = NULL
}
print(paste('dim of dummyimputedtrainFactor = ' ,dim(dummyimputedtrainFactor)))
library(caret)
dim(dummyimputedtrainFactor) # dimension of dataset
nzv <- nearZeroVar(dummyimputedtrainFactor[,1:ncol(dummyimputedtrainFactor)], uniqueCut=10) # identify columns that are "near zero"
d_filtered <- dummyimputedtrainFactor[,1:ncol(dummyimputedtrainFactor)][, -nzv]            # remove those columns from your dataset
dim(d_filtered)
dim(imputedtrainNumeric) # dimension of dataset
nzv1 <- nearZeroVar(imputedtrainNumeric[,1:ncol(imputedtrainNumeric)], uniqueCut=10) # identify columns that are "near zero"
d_filtered_numeric <- imputedtrainNumeric[,1:ncol(imputedtrainNumeric)][, -nzv1]            # remove those columns from your dataset
dim(d_filtered_numeric)
setdiff(names(imputedtrainNumeric), names(d_filtered_numeric))
table(imputedtrainNumeric$BsmtFinSF2)
# calculate correlation matrix using Pearson's correlation formula
descrCor <-  cor(d_filtered[,1:ncol(d_filtered)])                           # correlation matrix
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .85) # number of Xs having a corr > some value
summary(descrCor[upper.tri(descrCor)])  # summarize the correlations
highlyCorDescr <- findCorrelation(descrCor, cutoff = 0.85)
filteredDescr <- d_filtered[,1:ncol(d_filtered)][,-highlyCorDescr] # remove those specific columns from your dataset
descrCor2 <- cor(filteredDescr)                  # calculate a new correlation matrix
summary(descrCor2[upper.tri(descrCor2)])
descrCorNum <-  cor(d_filtered_numeric[,1:(ncol(d_filtered_numeric)-1)])                           # correlation matrix
highCorrNum <- sum(abs(descrCorNum[upper.tri(descrCorNum)]) > .85) # number of Xs having a corr > some value
summary(descrCorNum[upper.tri(descrCorNum)])  # summarize the correlations
highlyCorDescrNum <- findCorrelation(descrCorNum, cutoff = 0.85)
filteredDescrNumeric <- d_filtered_numeric[,1:ncol(d_filtered_numeric)][,-highlyCorDescrNum] # remove those specific columns from your dataset
descrCor2Numeric <- cor(filteredDescrNumeric)                  # calculate a new correlation matrix
summary(descrCor2Numeric[upper.tri(descrCor2Numeric)])
library(caret)
# create a column of 1s. This will help identify all the right linear combos
filteredDescr <- cbind(rep(1, nrow(filteredDescr)), filteredDescr[2:ncol(filteredDescr)])
names(filteredDescr)[1] <- "ones"
# identify the columns that are linear combos
comboInfo <- findLinearCombos(filteredDescr)
comboInfo
#filteredDescr[,'ones']=NULL
# create a column of 1s. This will help identify all the right linear combos
filteredDescrNumeric <- cbind(rep(1, nrow(filteredDescrNumeric)), filteredDescrNumeric[2:ncol(filteredDescrNumeric)])
names(filteredDescrNumeric)[1] <- "ones"
# identify the columns that are linear combos
comboInfo <- findLinearCombos(filteredDescr)
comboInfo
# Step 1) figures out the means, standard deviations, other parameters, etc. to
# transform each variable
preProcValues <- preProcess(filteredDescrNumeric[,1:(ncol(filteredDescrNumeric)-1)], method = c("center","scale"))
# Step 2) the predict() function actually does the transformation using the
# parameters identified in the previous step. Weird that it uses predict() to do
# this, but it does!
dNums <- predict(preProcValues, filteredDescrNumeric)
dNums[,'ones'] = NULL
filteredDescr[,'ones'] = NULL
filteredDescr$`Exterior1st_Wd Sdng`= NULL
modeldata = cbind(dNums,filteredDescr)
trainSet <- sample(nrow(modeldata), 0.75*nrow(modeldata), replace = FALSE)
TrainingSet <- modeldata[trainSet,]
ValidationSet <- modeldata[-trainSet,]
#summary(TrainingSet)
#summary(ValidationSet)
require(randomForest)
#names(TrainingSet)['Exterior1st_Wd Sdng'] <- "Exterior1st_Wd_Sdng"
# Create a Random Forest model with default parameters
model <- randomForest(SalePrice ~ ., data =TrainingSet, ntree = 500, mtry = 10  ,importance = TRUE)
model
plot(model$mse)
which.min(model$mse)
pred_randomForest <- predict(model, ValidationSet)
head(pred_randomForest)
sqrt(model$mse[which.min(model$mse)])
require(Metrics)
rmsle(ValidationSet$SalePrice, pred_randomForest)
library(xgboost)
x_train = TrainingSet[,-grep('SalePrice', colnames(TrainingSet))]
y_train = TrainingSet$SalePrice
dtrain <- data.matrix(x_train)
#dtrain = data.matrix(TrainingSet)
label = TrainingSet$SalePrice
xgb <- xgboost(data = data.matrix(x_train),
label = y_train,
eta = 0.1,
max_depth = 5,
nround=250,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "rmse",
objective = "reg:linear",
nthread = 3
)
dim(dtrain)
# predict values in test set
x_test = ValidationSet[,-grep('SalePrice', colnames(ValidationSet))]
y_test = ValidationSet$SalePrice
#validat = xgb.DMatrix(as.matrix(sapply(valida, as.numeric)), label=SalePrice)
y_pred <- predict(xgb, data.matrix(x_test))
require(Metrics)
rmsle(y_test, y_pred)
columnNames = names(test)
#print(columnNames)
#Initializing the separate dataframe to NULL so that in case of any error they don't keep previous records
testNumeric = NULL
testFactor = NULL
#Iterating over column names and putting it into appropriate basket
for (name in columnNames){
print(is.null(testFactor))
if('factor' == toString(class(test[[name]]))){
if(is.null(testFactor)){
testFactor = test[name]
}
testFactor[name] = test[[name]]
} else{
if(is.null(testNumeric)){
testNumeric = test[name]
}
testNumeric[name] = test[[name]]
}
}
dummyimputedtestFactor <- fastDummies::dummy_cols(testFactor, remove_first_dummy = FALSE)
colnames(testNumeric)
testFactorfilt <- dummyimputedtestFactor[,colnames(filteredDescr)]
testNumericfilt <- testNumeric[setdiff(colnames(dNums),"SalePrice")]
#names(dummyimputedtestFactor)
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(testFactorfilt,2,pMiss)
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(testNumericfilt,2,pMiss)
require(mice)
imputertestNum <- mice(testNumericfilt,m=1,maxit=1,meth='cart')
#summary(imputerF)
imputedtestNumeric = complete(imputertestNum, 1)
apply(imputedtestNumeric,2,pMiss)
preProcValuesF <- preProcess(imputedtestNumeric[,1:(ncol(imputedtestNumeric))], method = c("center","scale"))
# Step 2) the predict() function actually does the transformation using the
# parameters identified in the previous step. Weird that it uses predict() to do
# this, but it does!
dNumsF <- predict(preProcValuesF, imputedtestNumeric)
finalTestData = cbind(dNumsF,testFactorfilt)
pred_randomForest_test<- predict(model, finalTestData)
head(pred_randomForest)
sqrt(model$mse[which.min(model$mse)])
mf <- lm(y ~ ., data=modeldata)
mf <- lm(SalePrice ~ ., data=modeldata)
summary(mf)
library(leaps)
install.packages('leaps')
library(leaps)
mb <- regsubsets(SalePrice ~ ., data=TrainingSet
, nbest=1
, intercept=T
, method='backward'
, really.big=T
)
View(mb)
vars2keep <- data.frame(summary(mb)$which[which.max(summary(mb)$adjr2),])
View(vars2keep)
View(mb)
View(vars2keep)
summary(mb)$adjr2
which.max(summary(mb)$adjr2)
summary(mb)$which[which.max(summary(mb)$adjr2),]
vars2keep <- data.frame(summary(mb)$which[which.max(summary(mb)$adjr2),])
names(vars2keep) <- c("keep")
head(vars2keep)
View(vars2keep)
vars2keep <- setDT(vars2keep, keep.rownames=T)[]
View(vars2keep)
vars2keep <- c(vars2keep[which(vars2keep$keep==T & vars2keep$rn!="(Intercept)"),"rn"])[[1]]
vars2keep
library(caret)
ctrl <- trainControl(method="cv",     # cross-validation set approach to use
number=3,        # k number of times to do k-fold
classProbs = F,
summaryFunction = defaultSummary,
allowParallel=T)
lassofit <- train(y ~ .,
data = TrainingSet,
method = "lars",
trControl = ctrl,
#preProcess=c("center","scale"), # not needed; already transformed
tuneLength = 15,                # this specifies various s values
metric = "RMSE")
lassofit <- train(SalePrice ~ .,
data = TrainingSet,
method = "lars",
trControl = ctrl,
#preProcess=c("center","scale"), # not needed; already transformed
tuneLength = 15,                # this specifies various s values
metric = "RMSE")
plot(lassofit$finalModel)
lassofit$bestTune[[1]]
plot(x=lassofit$results$fraction, y=lassofit$results$RMSE
, col="blue", pch=19
, main="RMSE vs s from caret runs", xlab="S", ylab="RMSE")
rf <- train(SalePrice ~ .,
data = TrainingSet,
method = "rf",
importance=T,    # we add this in or it varImp cannot be computed
trControl = ctrl,
tuneLength = 10,
metric = "RMSE"
)
rf
mb_pred1 <- predict(mb, train)
mb_pred1 <- predict(mb, TrainingSet)
